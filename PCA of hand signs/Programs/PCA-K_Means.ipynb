{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Algorithm to distinguish different hand signs extended with K-Means\n",
    "By Mailin Brandt and Finian landes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads Images from dir, size has to be provided (image in format size x size)\n",
    "#returns images as vectors and image names as list\n",
    "def load_images(dir: str, size: int = 256, grayscale: bool = True) -> np.ndarray:\n",
    "    image_names: list = sorted(os.listdir(dir))\n",
    "    n: int = len(image_names)\n",
    "    images: np.ndarray = np.zeros([n, size ** 2])\n",
    "    for i, name in enumerate(image_names):\n",
    "        img: Image = Image.open(dir + \"//\"+ name)\n",
    "        images[i] = img.getdata(0)\n",
    "    return images, np.array(image_names)\n",
    "\n",
    "#Generates a random train and test set with n_test test items\n",
    "#returns train and test images and train and test names\n",
    "def get_train_test_dataset(images: np.ndarray, image_names: list[str], n_test: int) -> tuple[np.ndarray, np.ndarray, list, list]:\n",
    "    indices: list = np.random.choice(len(images), n_test, replace = False)\n",
    "    test: np.ndarray = images[indices]\n",
    "    names_test: list[str] = image_names[indices]\n",
    "    train: np.ndarray = np.delete(images, indices, axis = 0)\n",
    "    names_train: list[str] = np.delete(image_names, indices)\n",
    "    return train, test, names_train, names_test\n",
    "\n",
    "#Using the coeff_matrix, the eigenfaces and the meanface returns the index of the image which lies closest to point\n",
    "#Returns index of closest image\n",
    "def closest_neighbour(point: np.ndarray, meanface: np.ndarray , eigenfaces: np.ndarray, coeff_mat: np.ndarray) -> int:\n",
    "    c1: np.ndarray = np.matmul(eigenfaces, point - meanface)\n",
    "    distances: np.ndarray = np.sum((c1 - coeff_mat.T)**2, axis=1)\n",
    "    return np.argmin(distances)\n",
    "\n",
    "#Creates a matrix from the meanface, the eigenfaces and the passed points, which is used to increase efficiency of the PCA-Algorithm\n",
    "#Returns a matrix in form n x n where n is the number of images\n",
    "def coeff_matrix(meanface: np.ndarray, eigenfaces: np.ndarray, points: np.ndarray) -> np.ndarray:\n",
    "    return np.matmul(eigenfaces, (points - meanface).T)\n",
    "\n",
    "#Saves an image with a given filename stable for image in any format \n",
    "#Returns None\n",
    "def save_image(picture: np.ndarray, filename: str, location: str = \"c:/Users/finia/OneDrive - SBL/PrA/PCA of hand signs/Processed Images/Eigenfaces\", size: int = 256) -> None:\n",
    "    min_val: float = np.min(picture)\n",
    "    picture = picture - min_val\n",
    "    picture = picture / np.max(picture)\n",
    "    picture = (255 * picture).astype(np.uint8)\n",
    "    n_picture = np.reshape(picture, (size, size)).astype(dtype = np.uint8)\n",
    "    plt.imshow(n_picture, cmap = \"gray\")\n",
    "    plt.show()\n",
    "    im = Image.fromarray(n_picture, mode=\"L\")\n",
    "    im.save(location + \"/\" + filename + \".jpg\")\n",
    "\n",
    "#Initializes centroids for K-Means by choosing k random points\n",
    "#Returns k centroids\n",
    "def init_centroids(k: int, points: np.ndarray) -> np.ndarray:\n",
    "    centroids: np.ndarray = points[np.random.choice(len(points), k, replace = False)]\n",
    "    return centroids\n",
    "\n",
    "#Run K-means\n",
    "#Returns new centroids and the classification of the points\n",
    "def run_iteration(points: np.ndarray, centroids: np.ndarray, k: int) -> tuple[np.ndarray, list]:\n",
    "    classification: list = []\n",
    "    clusters: list[np.ndarray] = [[] for _ in range(k)]\n",
    "    new_centroids: np.ndarray = np.zeros((k, points.shape[1]))\n",
    "\n",
    "    for point in points:\n",
    "        distances: list[np.ndarray] = [np.linalg.norm(point - centroid) for centroid in centroids]\n",
    "        classification.append(np.argmin(distances))\n",
    "        clusters[classification[-1]].append(point)\n",
    "    for i in range(len(centroids)):\n",
    "        if len(clusters[i]) == 0:\n",
    "            new_centroids[i] = points[np.random.randint(0, points.shape[0])]\n",
    "        else:\n",
    "            new_centroids[i] = np.mean(clusters[i], axis = 0)\n",
    "    return classification, new_centroids\n",
    "\n",
    "#Checks whether k-means is converged by comparing the distances between the old and the new centroids\n",
    "#Returns True when K-means is NOT converged\n",
    "def is_not_converged(last_centroids: np.ndarray, current_centroids: np.ndarray, e: float = 1e-20) -> bool:\n",
    "    dist: float = 0\n",
    "    for  i in range(len(last_centroids)):\n",
    "        dist += np.sqrt(np.sum((last_centroids[i] - current_centroids[i]) ** 2))\n",
    "    return dist > e\n",
    "\n",
    "#Clusters the names of the images using the classification of the points\n",
    "#Returns list with the names of images in each cluster, where each cluster is depicted by a sublist\n",
    "def cluster_names(classification: list, names: list, k: int) -> list:\n",
    "    classified_names: list = [[] for _ in range(k)]\n",
    "    for i, name in enumerate(names):\n",
    "        classified_names[classification[i]].append(name)\n",
    "    return classified_names\n",
    "\n",
    "#Computes coefficients from a point a mean and a point array\n",
    "#Returns those coefficients as np.array\n",
    "def compute_coefficients(point: np.ndarray, points: np.ndarray, mean: np.ndarray) -> np.ndarray:\n",
    "    return np.matmul(points, point - mean)\n",
    "\n",
    "#Calculates the distance between a point and a mean by additionally using a points array to make a transformation in space to make the eclidean distance more meaningful\n",
    "#Returns the distance as float\n",
    "def distance(point: np.ndarray, q: np.ndarray, mean: np.ndarray, points: np.ndarray) -> float:\n",
    "    c1: np.ndarray = compute_coefficients(point, points, mean)\n",
    "    c2: np.ndarray = compute_coefficients(q, points, mean)\n",
    "    return np.sqrt(np.sum((c1 - c2)**2))\n",
    "\n",
    "#Calculates the distance between each point and a given center point \n",
    "#Returns the distances of each point to the center point\n",
    "def outlying_distances(center: np.ndarray, points: np.ndarray) -> list:\n",
    "    dist: list = [distance(point, np.zeros_like(point), center, points) for point in points]\n",
    "    return dist\n",
    "\n",
    "#Sorts points by taking their distance to a given center and then ordering them in ascending order \n",
    "#Returns the Distances and the sorted points aswell as the sorted names\n",
    "def sort_points_names_by_dist(center: np.ndarray, points: np.ndarray, names: list) -> tuple[np.ndarray, np.ndarray, list]:\n",
    "    distances: list = np.array(outlying_distances(center, points))\n",
    "    new_names: np.ndarray = np.array(names)\n",
    "    sorted_indicies: list = np.argsort(distances)\n",
    "    distances: list = list(distances[sorted_indicies])\n",
    "    new_names: list = list(new_names[sorted_indicies])\n",
    "    points: np.ndarray = points[sorted_indicies]\n",
    "    return distances, points, new_names\n",
    "\n",
    "#Creats a count of how often each kind appears in each cluster\n",
    "#Returns a list with dicts containig the count of items and also a score where 100% means that all clusters only contain one kind and 0% means that all kinds are distributed evenly\n",
    "def k_means_score(cluster_names: list) -> tuple[list, float]:\n",
    "    cluster_names: list = [[name[:-7] for name in sublist] for sublist in cluster_names]\n",
    "    all_names: list = [item for sublist in cluster_names for item in sublist]\n",
    "    without_duplicates: list = list(dict.fromkeys(all_names))\n",
    "    result: list = []\n",
    "    for sublist in cluster_names:\n",
    "        count_dict: dict = {name: sublist.count(name) for name in without_duplicates}\n",
    "        result.append(count_dict)\n",
    "    total_items: int = len(all_names)\n",
    "    max_counts: list = [max(cluster.values()) for cluster in result]\n",
    "    actual_score: int = sum(max_counts)\n",
    "    normalized_score: float = round(actual_score / total_items, 2)\n",
    "    return result, normalized_score\n",
    "\n",
    "#Get succeses in prediticting the right name for a test point by looking at its closest distance to a centroid\n",
    "#Returns the percentage of successes of guessing the point in test correct\n",
    "def get_successes(centroids: np.ndarray, test: np.ndarray, distribution: list, test_name: list) -> float:\n",
    "    successes: int = 0\n",
    "    for i, point in enumerate(test):\n",
    "        i_centroid: int = np.argmin([np.linalg.norm(point - centroid) for centroid in centroids])\n",
    "        pred_name: str = max(distribution[i_centroid], key=distribution[i_centroid].get)\n",
    "        real_name: str = test_name[i][:-7]\n",
    "        certainty: float = distribution[i_centroid][pred_name] / sum(distribution[i_centroid].values())\n",
    "        #print(pred_name, real_name, round(certainty, 2) * 100)\n",
    "        successes += (pred_name == real_name)\n",
    "    return round(successes / len(test), 2)\n",
    "\n",
    "#Run K-Means with sklearn to test performace\n",
    "#Returns classification and the centroids\n",
    "def sklearn_kmeans(points: np.ndarray, k: int, init = \"k-means++\") -> tuple[list, np.ndarray]:\n",
    "    kmeans: KMeans = KMeans(n_clusters=k, init=init, random_state=42)\n",
    "    classification_sklearn: list = kmeans.fit_predict(points)\n",
    "    centroids_sklearn: np.ndarray = kmeans.cluster_centers_\n",
    "    return classification_sklearn, centroids_sklearn\n",
    "\n",
    "#From a list with sublists containing image names, copies those images into numareted folders\n",
    "#Returns None\n",
    "def order_save_images(cluster_n: list, top_folder_path: str = \"C:/Users/finia/OneDrive - SBL/PrA/PCA of hand signs/Processed Images/Results\", folder_prefix: str = \"Cluster_\", current_image_folder_path: str = \"c:/Users/finia/OneDrive - SBL/PrA/PCA of hand signs/Processed Images/Train\") -> None:\n",
    "    for i, cluster in enumerate(cluster_n):\n",
    "        folder_name: str = folder_prefix + str(i)\n",
    "        folder_path: str = top_folder_path + \"/\" + folder_name\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        for image_name in cluster:\n",
    "            shutil.copy(current_image_folder_path +\"/\"+ image_name, folder_path+ \"/\" + image_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir_train: str = \"c:/Users/finia/OneDrive - SBL/PrA/PCA of hand signs/Processed Images/Train/\"\n",
    "image_dir_test: str = \"c:/Users/finia/OneDrive - SBL/PrA/PCA of hand signs/Processed Images/Test\"\n",
    "n_test_images: int = 50\n",
    "train, names_train = load_images(image_dir_train)\n",
    "test, names_test = load_images(image_dir_test)\n",
    "#train, test, names_train, names_test = get_train_test_dataset(images, image_names, n_test_images)\n",
    "k: int = 15\n",
    "#train = (train - np.mean(train)) / np.std(train)\n",
    "dimensions: np.ndarray = train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanface: np.ndarray = np.mean(train, axis=0)\n",
    "A: np.ndarray = train - meanface\n",
    "eigenfaces, s, VT = np.linalg.svd(A.transpose(), full_matrices=False)\n",
    "eigenfaces: np.ndarray = eigenfaces.transpose()\n",
    "coeff_mat: np.ndarray = coeff_matrix(meanface, eigenfaces, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means score: 79.0%\n"
     ]
    }
   ],
   "source": [
    "points: np.ndarray = coeff_mat.T\n",
    "classification: list = []\n",
    "centroids: np.ndarray = init_centroids(k, points)\n",
    "init_cent: np.ndarray = centroids.copy()\n",
    "last_centroids: np.ndarray = np.zeros_like(centroids)\n",
    "\n",
    "while is_not_converged(last_centroids, centroids):\n",
    "    last_centroids = centroids.copy()\n",
    "    classification, centroids = run_iteration(points, centroids, k)\n",
    "\n",
    "cluster_n: list = cluster_names(classification, names_train, k)\n",
    "distribution, score = k_means_score(cluster_n)\n",
    "print(\"K-Means score: \" + str(score * 100) + \"%\")\n",
    "\n",
    "#for i in range(5):\n",
    "    #save_image(meanface + np.matmul(centroids[i], eigenfaces), \"k_means_\" + str(i + 1))\n",
    "    \n",
    "#order_save_images(cluster_n)\n",
    "#print(\"Successes K-Means: \" + str(get_successes(np.matmul(centroids, eigenfaces), test, distribution, names_test) * 100) + \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification_sklearn, centroids_sklearn = sklearn_kmeans(points, k)\n",
    "#cluster_n_sklearn: list = cluster_names(classification_sklearn, names_train, k)\n",
    "#distribution_sklearn, score_sklearn = k_means_score(cluster_n_sklearn)\n",
    "#print(\"K-Means score sklearn: \" + str(score_sklearn * 100) + \"%\")\n",
    "order_save_images(cluster_n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
